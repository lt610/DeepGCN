<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="">
    <meta name="description" content="">
    <title>详细报告语句详情</title>
    <link href="../css/bootstrap.min.css" rel="stylesheet" />
    <link href="../css/style.css" rel="stylesheet" />
    <style type="text/css">
        .content-tips .paper-section{margin-bottom:0;min-width:450px;}
    </style>
</head>
<body>
<span id="gototop"></span>
<div>
    <div class="paper-txt P30">
        <div class="paper-section" style="margin-bottom:0;">
            <div class="font-bold MT5">
                该句相似度：<span class="g-font-color red similarNum">81%</span>
            </div>
            <div class="MT30">
                <p class="font-bold">您的语句：</p>
                <span>根据大数定理理论，当训练集的规模趋向于无穷大时，经验风险也会趋向于期望风险。</span>
            </div>
        </div>
    </div>
    <div>
        <div class="tab-A">
            <ul class="tab-A-ul clearfix" tab-a="ul">
                                        <li class="active" data-id="学术期刊,学位论文,学术会议,书籍数据,互联网,自建库,all">
                            <span class="tab-text">综合</span>
                            <span class="tab-superscript">15</span>
                        </li>
                                    <li data-id="tab,学术期刊,学位论文,学术会议,书籍数据,自建库,local"
                                    >
                    <span class="tab-text">本地库</span>
                    <span class="tab-superscript">14</span>
                </li>
                                <li data-id="互联网,5">
                    <span class="tab-text">互联网</span>
                    <span class="tab-superscript">1</span>
                </li>
                            </ul>
        </div>
        <div class="none" tab="section" data-id="tab"
                    >
            <div class="tab-B clearfix">
                <div class="paper-section P30 PB0 clearfix" style="padding:30px 10px 0">
                <ul class="tab-B-ul pull-left clearfix" tab-b="ul">
                        <li class="active" data-id="tab,学术期刊,学位论文,学术会议,书籍数据,自建库,local">
                            <span class="tab-text">全部</span>
                            <span class="tab-superscript">14</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,学术期刊,1">
                            <span class="tab-text">期刊</span>
                            <span class="tab-superscript">1</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,学位论文,2">
                            <span class="tab-text">学位</span>
                            <span class="tab-superscript">13</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,学术会议,3">
                            <span class="tab-text">会议</span>
                            <span class="tab-superscript">0</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,书籍数据,4">
                            <span class="tab-text">图书</span>
                            <span class="tab-superscript">0</span>
                                                    </li>
                                            </ul>
                </div>
                <div class="g-line-row MT30 tab-pane-line"></div>
            </div>
        </div>
        <div class="content-tips">
            <div class="tab-content none" tab="section" data-id="1">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在期刊库共找出相似内容：<span>1</span>个                    <p>
                                        <div style="margin-top: 10px;">
                    <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>
                    </div>
                                    </div>
            </div>

            <div class="tab-content none" tab="section" data-id="2">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在学位库共找出相似内容：<span>13</span>个                    <p>
                                        <div style="margin-top: 10px;">
                    <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>                    </div>
                                    </div>
            </div>
            <div class="tab-content none" tab="section" data-id="3">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在会议库中没有找到与此句话相似的内容                    <p>
                                        <div style="margin-top: 10px;">
                                        </div>
                                    </div>
            </div>
            <div class="tab-content none" tab="section" data-id="4">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在图书库中没有找到与此句话相似的内容                    <p>
                                        <div style="margin-top: 10px;">
                                        </div>
                                    </div>
            </div>
            <div class="tab-content none" tab="section" data-id="5">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在互联网库共找出相似内容：<span>1</span>个                    <p>
                                        <div style="margin-top: 10px;">
                    <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>                    </div>
                                    </div>
            </div>
            <!-- 自建库 -->
            <div class="tab-content none" tab="section" data-id="6">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在自建库中没有找到与此句话相似的内容                    <p>
                                        <div style="margin-top: 10px;">
                                        </div>
                                    </div>
            </div>
                        <div class="tab-content" tab="section" data-id="all">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                                                在本地库和互联网库共找出相似内容：<span>15</span>个
                                            <p>
                                            <div style="margin-top: 10px;">
                    <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>

                    </div>
                                    </div>
            </div>
            <div class="tab-content none" tab="section" data-id="local">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在本地库共找出相似内容：<span>14</span>个                    <p>
                                        <div style="margin-top: 10px;">
                    <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>
                    </div>
                                    </div>
            </div>
        </div>



                <div class="tab-content" tab="section" data-id="互联网">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">1</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color red similarNum">81%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color red"><span class="g-underline-text">根据</span><span class="g-underline-text"><span class="g-underline-text">大</span>数</span><span class="g-underline-text">定理</span>理论，<span class="g-underline-text">当</span><span class="g-underline-text">训练</span><span class="g-underline-text">集</span>的规模<span class="g-underline-text">趋向</span><span class="g-underline-text">于</span><span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>也会<span class="g-underline-text">趋向</span><span class="g-underline-text">于</span><span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">。<span class="g-underline-text">根据</span><span class="g-underline-text"><span class="g-underline-text">大</span>数</span><span class="g-underline-text">定理</span>可知，<span class="g-underline-text">当</span><span class="g-underline-text">训练</span><span class="g-underline-text">集</span><span class="g-underline-text">大</span>小D<span class="g-underline-text">趋向</span><span class="g-underline-text">于</span><span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>就<span class="g-underline-text">趋向</span><span class="g-underline-text">于</span><span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            （EmpiricalRisk），即在训练集上的平均损失。因此，一个切实可行的学习准则是找到一组参数θ�6�5使得经验风险最小，这就是经验风险最小化（EmpiricalRiskMinimization，ERM）准则<span class="g-font-color green">。根据大数定理可知，当训练集大小D趋向于无穷大时，经验风险就趋向于期望风险。</span>然而通常情况下，训练样本往往是真实数据的一个很小的子集或者包含一定的噪声数据，不能很好地                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（互联网）：</p>
                            <div class="local-source-detail">
                                <b>标题：</b>nndl 读书笔记 第2章 机器学习概述 - 简书<br/><a href='https://www.jianshu.com/p/d812aed316ea' target='_blank'>https://www.jianshu.com/p/d812aed316ea</a>
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">2</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">60%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">根据<span class="g-underline-text"><span class="g-underline-text">大</span>数</span><span class="g-underline-text">定理</span>理论，<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>集<span class="g-underline-text">的</span>规模趋向于<span class="g-underline-text">无穷</span><span class="g-underline-text">大</span>时，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>也会趋向于<span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">依据是<span class="g-underline-text"><span class="g-underline-text">大</span>数</span><span class="g-underline-text">定理</span>，只有<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>样本趋近于<span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">的</span>时候，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>才趋近于<span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。即：</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            ，就是所谓的经验风险最小化(ERM)准则。仔细研究经验风险最小化准则[71]和机器学习问题中的期望风险最小化要求，可以发现，从期望风险最小化到经验风险最小化的理论<span class="g-font-color green">依据是大数定理，只有当训练样本趋近于无穷大的时候，经验风险才趋近于期望风险。即：</span>尽管如此，在没有新的机器学习理论诞生之前，经验风险最小化作为机器学习问题基本的思想统治了                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《燃煤电站锅炉低NOx燃烧优化运行策略的研究》<br><b>作者：</b>魏辉<br><b>分类号：</b>TK227.6<br><b>学科专业：</b>热能工程<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>罗永浩<br><b>学位授予单位：</b>上海交通大学<br><b>学位年度：</b>2008<br><b>关键词：</b>燃煤电站锅炉 燃烧优化 低Nox排放 锅炉效率预测模型 集散控制系统 BP神经网络
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">3</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">58%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">根据<span class="g-underline-text"><span class="g-underline-text">大</span>数</span><span class="g-underline-text">定理</span>理论，<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>集<span class="g-underline-text">的</span>规模趋向于<span class="g-underline-text">无穷</span><span class="g-underline-text">大</span>时，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>也会趋向于<span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">依据是<span class="g-underline-text"><span class="g-underline-text">大</span>数</span><span class="g-underline-text">定理</span>，只有<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>样本趋近于<span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">的</span>时候，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>才趋近于<span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。即</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            最小值，就是所谓的经验风险最小化(ERM)准则。仔细研究经验风险最小化准则和机器学习问题中的期望风险最小化要求，可以发现，从期望风险最小化到经验风险最小化的理论<span class="g-font-color green">依据是大数定理，只有当训练样本趋近于无穷大的时候，经验风险才趋近于期望风险。即</span>：尽管如此，在没有新的机器学习理论诞生之前，经验风险最小化作为机器学习问题基本的思想                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《支持向量回归机算法理论研究与应用》<br><b>作者：</b>曾绍华<br><b>分类号：</b>O221.4<br><b>学科专业：</b>控制理论与控制工程<br><b>授予学位：</b>博士<br><b>导师姓名：</b>曹长修<br><b>学位授予单位：</b>重庆大学<br><b>学位年度：</b>2006<br><b>关键词：</b>支持向量机 组合优化 整数规划 异常数据 故障检测 目标变量 模式分类
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">4</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">53%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">根据<span class="g-underline-text">大</span>数定理理论，<span class="g-underline-text">当</span>训练集<span class="g-underline-text">的</span>规模<span class="g-underline-text">趋向</span><span class="g-underline-text">于</span><span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>也会<span class="g-underline-text">趋向</span><span class="g-underline-text">于</span><span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">接近<span class="g-underline-text">期望</span><span class="g-underline-text">的</span>最优解，<span class="g-underline-text">当</span>，<span class="g-underline-text">趋向</span><span class="g-underline-text">于</span><span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>就等同<span class="g-underline-text">于</span><span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。这～</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            之间的误差偏大，用经验风险最小化得到的最优解可能具有较差的推广性；如果样本个数，较大，郑州人学博I?学位论文则置信范围就会很小，经验风险最小化的最优解就<span class="g-font-color green">接近期望的最优解，当，趋向于无穷大时，经验风险就等同于期望风险。这～</span>结论从侧面证明了经验风险代替期望风险最小化要满足大数定理。同时从式(3．9)也                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于支持向量机的岩体力学参数反演及工程应用》<br><b>作者：</b>李晓龙<br><b>分类号：</b>TU45<br><b>学科专业：</b>水工结构工程<br><b>授予学位：</b>博士<br><b>导师姓名：</b>王复明<br><b>学位授予单位：</b>郑州大学<br><b>学位年度：</b>2009<br><b>关键词：</b>岩体力学 参数反演 支持向量机 核函数 粒子群算法
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">5</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">49%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">根据<span class="g-underline-text">大</span>数定理理论，<span class="g-underline-text">当</span>训练集<span class="g-underline-text">的</span>规模<span class="g-underline-text">趋向</span><span class="g-underline-text">于</span><span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>也会<span class="g-underline-text">趋向</span><span class="g-underline-text">于</span><span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">过程或学习算法，<span class="g-underline-text">当</span>样本数<span class="g-underline-text">趋向</span><span class="g-underline-text">于</span><span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，其<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span><span class="g-underline-text">的</span>最小值收敛<span class="g-underline-text">于</span><span class="g-underline-text">期望</span><span class="g-underline-text">风险</span><span class="g-underline-text">的</span></p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            收敛速度是快的。第20页万方数据第二章图像分类理论及其方法上述定理被称作是学习理论的三个里程碑。在不同程度上回答了在什么条件下，一个遵循经验风险最小化原则的学习<span class="g-font-color green">过程或学习算法，当样本数趋向于无穷大时，其经验风险的最小值收敛于期望风险的</span>最小值，而且收敛速度是快的。进一步，引入另一指标VC维。若存在一个有h个样本                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《图像分类和图像匹配中若干问题的研究》<br><b>作者：</b>吴迪<br><b>分类号：</b>TP391.41<br><b>学科专业：</b>通信与信息系统<br><b>授予学位：</b>博士<br><b>导师姓名：</b>张文军<br><b>学位授予单位：</b>上海交通大学<br><b>学位年度：</b>2009<br><b>关键词：</b>图像分类 图像匹配 支持向量机 抽样选择偏差 核密度估计 遗传算法 特征提取
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">6</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">48%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">根据<span class="g-underline-text"><span class="g-underline-text">大</span>数</span>定理理论，<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>集<span class="g-underline-text">的</span>规模趋向于<span class="g-underline-text">无穷</span><span class="g-underline-text">大</span>时，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>也会趋向于<span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">是<span class="g-underline-text"><span class="g-underline-text">大</span>数</span>定律，只有<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>样本数目趋于<span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">的</span>时候才成立，此时<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>才趋于<span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>，</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            即经验数据)定义的，因此称之为经验风险。用求经验a最小值代替求期望风险R()a的最小值，就是经验风险最小化准则[20]式（2-1-2）所依据的<span class="g-font-color green">是大数定律，只有当训练样本数目趋于无穷大的时候才成立，此时经验风险才趋于期望风险，</span>即在统计学习理论出现以前，经验风险最小化准则一直是机器学习问题所追求的目万方数据第二章                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于SVR的旋转机械转子早期故障预示方法研究》<br><b>作者：</b>秦启茂<br><b>分类号：</b>TP181<br><b>学科专业：</b>机械制造及其自动化<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>宋宜梅<br><b>学位授予单位：</b>桂林电子科技大学<br><b>学位年度：</b>2010<br><b>关键词：</b>旋转机械 转子结构 故障诊断 支持向量机 BP神经网络
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">7</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">47%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">根据<span class="g-underline-text">大数</span><span class="g-underline-text">定理</span>理论，<span class="g-underline-text">当</span>训练<span class="g-underline-text">集</span>的规模趋向于<span class="g-underline-text">无穷</span>大<span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>也会趋向于<span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">。依据<span class="g-underline-text">大数</span><span class="g-underline-text">定理</span>，<span class="g-underline-text">当</span>样本<span class="g-underline-text">集</span>个数趋于<span class="g-underline-text">无穷</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>近似为<span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。利用<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>最小来</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            无法计算的。在一般的机器学习算法中，往往利用有限训练数据样本集的误差的平均值来代替，称之为经验风险。mmi，则经验风险()w定义为：xw为机器学习算法的损失函数<span class="g-font-color green">。依据大数定理，当样本集个数趋于无穷时，经验风险近似为期望风险。利用经验风险最小来</span>优化机器学习模型的方法称作经验风险最优（EmpiricalRiskMinization，ERM）原则。其中，早期的神经网络模型的                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于机器学习的车联网资源分配机制研究》<br><b>作者：</b>刘聪<br><b>学科专业：</b>电子与通信工程<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>周起设<br><b>学位授予单位：</b>西安电子科技大学<br><b>学位年度：</b>2017
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">8</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">46%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">根据<span class="g-underline-text">大</span>数定理理论，<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>集<span class="g-underline-text">的</span>规模<span class="g-underline-text">趋向</span><span class="g-underline-text">于</span><span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>也会<span class="g-underline-text">趋向</span><span class="g-underline-text">于</span><span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">性，是指<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>样本数目<span class="g-underline-text">趋向</span><span class="g-underline-text">于</span><span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span><span class="g-underline-text">的</span>最优值能够收敛到<span class="g-underline-text">期望</span><span class="g-underline-text">风险</span><span class="g-underline-text">的</span></p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            前三部分的结论，在分类和拟合问题中构造现实的学习算法，它遵循SRM原则，从而较传统算法有更好的泛化能力。1．3．3学习过程的一致性条件所谓学习过程的一致<span class="g-font-color green">性，是指当训练样本数目趋向于无穷大时，经验风险的最优值能够收敛到期望风险的</span>最优值。只有满足一致性条件，才能保证在ERM原则下得到的最优方法当样本趋于无穷时，趋近                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于支持向量机的代价敏感数据挖掘研究与应用》<br><b>作者：</b>郑恩辉<br><b>分类号：</b>O234<br><b>学科专业：</b>控制科学与工程<br><b>授予学位：</b>博士<br><b>导师姓名：</b>宋执环<br><b>学位授予单位：</b>浙江大学<br><b>学位年度：</b>2006<br><b>关键词：</b>数据挖掘 代价敏感 支持向量机 统计学习理论
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">9</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">46%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">根据大数定理理论，<span class="g-underline-text">当</span>训练集<span class="g-underline-text">的</span>规模<span class="g-underline-text">趋向</span><span class="g-underline-text">于</span>无穷大时，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span><span class="g-underline-text">也</span>会<span class="g-underline-text">趋向</span><span class="g-underline-text">于</span><span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">的</span>VC维较低，<span class="g-underline-text">当</span>样本数较少时，置信范围<span class="g-underline-text">也</span>较小，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span><span class="g-underline-text">也</span><span class="g-underline-text">趋向</span><span class="g-underline-text">于</span><span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            得不到好的效果【张学工，2000]。对于模式识别问题，虽然很多情况不是线性的，但是当样本数量有限时，我们用线性分类器往往能得到不错的结果，其原因就是线性分类器<span class="g-font-color green">的VC维较低，当样本数较少时，置信范围也较小，经验风险也趋向于期望风险。</span>另一方面对于同一个数据集，我们比较各种算法的过程实际上是优化置信范围的过程，如果一种                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于支持向量机的过程工业数据挖掘技术研究》<br><b>作者：</b>张英<br><b>分类号：</b>TP181<br><b>学科专业：</b>控制理论与控制工程<br><b>授予学位：</b>博士<br><b>导师姓名：</b>苏宏业<br><b>学位授予单位：</b>浙江大学<br><b>学位年度：</b>2005<br><b>关键词：</b>过程工业 数据挖掘 支持向量机 精对苯二甲酸
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">10</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">46%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">根据<span class="g-underline-text">大</span>数定理理论，<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>集<span class="g-underline-text">的</span>规模趋向<span class="g-underline-text">于</span><span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>也会趋向<span class="g-underline-text">于</span>期望<span class="g-underline-text">风险</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">学习一致性<span class="g-underline-text">的</span>条件，即<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>样本数目趋<span class="g-underline-text">于</span><span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span><span class="g-underline-text">的</span>最优值收敛<span class="g-underline-text">于</span>实际<span class="g-underline-text">风险</span></p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            遗憾的是，至今尚没有通用的关于求解任意函数集VC维的方法，只是对一些特殊的函数集知道2．3．3推广能力的界统计学习理论中一个重要内容是研究经验风险最小化下统计<span class="g-font-color green">学习一致性的条件，即当训练样本数目趋于无穷大时，经验风险的最优值收敛于实际风险</span>最优值的条件。只有满足一致性条件，才能保证当样本数无穷大时，在经验风险最小化原则                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《支持向量机及其在汽轮机组性能监测和故障诊断中的应用研究》<br><b>作者：</b>王雷<br><b>分类号：</b>TP277<br><b>学科专业：</b>热能工程<br><b>授予学位：</b>博士<br><b>导师姓名：</b>徐治皋<br><b>学位授予单位：</b>东南大学<br><b>学位年度：</b>2007<br><b>关键词：</b>发电厂 汽轮机组 支持向量机 性能监测 时间序列预测 故障诊断
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">11</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">46%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">根据<span class="g-underline-text">大</span>数定理理论，<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>集<span class="g-underline-text">的</span>规模趋向<span class="g-underline-text">于</span><span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>也会趋向<span class="g-underline-text">于</span>期望<span class="g-underline-text">风险</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">学习一致性<span class="g-underline-text">的</span>条件，即<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>样本数目趋<span class="g-underline-text">于</span><span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span><span class="g-underline-text">的</span>最优值收敛<span class="g-underline-text">于</span>真实<span class="g-underline-text">风险</span></p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            应用统计学习理论时，可以通过变通的办法巧妙地避开直接求VC维的问题。图2.1一组两维数据分布z泛化性能的界统计学习理论中一个重要内容是研究经验风险最小化下统计<span class="g-font-color green">学习一致性的条件，即当训练样本数目趋于无穷大时，经验风险的最优值收敛于真实风险</span>最优值的条件。只有满足一致性条件，才能保证在经验风险最小化原则下得到最优结果，当样本                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于支持向量机的水电机组故障诊断研究》<br><b>作者：</b>邹敏<br><b>分类号：</b>TP277<br><b>学科专业：</b>水利水电工程<br><b>授予学位：</b>博士<br><b>导师姓名：</b>周建中<br><b>学位授予单位：</b>华中科技大学<br><b>学位年度：</b>2007<br><b>关键词：</b>水力发电 水电机组 故障诊断 支持向量机
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">12</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">46%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">根据大数定理<span class="g-underline-text">理论</span>，<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>集的规模趋向<span class="g-underline-text">于</span><span class="g-underline-text">无穷</span>大时，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>也会趋向<span class="g-underline-text">于</span>期望<span class="g-underline-text">风险</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">用均方误差表示。<span class="g-underline-text">理论</span>表明，<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>样本趋<span class="g-underline-text">于</span><span class="g-underline-text">无穷</span>多时，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>收敛<span class="g-underline-text">于</span>实际<span class="g-underline-text">风险</span>。因此</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            、技术到社会、经济等各领域中都具有十分广阔的应用前景。传统的学习理论主要是基于经验风险最小化原贝JJ(ERM)的。所谓经验风险，是指在训练集上的风险，通常<span class="g-font-color green">用均方误差表示。理论表明，当训练样本趋于无穷多时，经验风险收敛于实际风险。因此</span>经验风险最小化原则隐含地使用了训练样本无穷多的假设条件。然而，在实际应用中，如故障                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于支持向量机集成的故障诊断方法研究》<br><b>作者：</b>佘传伏<br><b>分类号：</b>TP181<br><b>学科专业：</b>机械制造及其自动化<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>俞立钧<br><b>学位授予单位：</b>上海大学<br><b>学位年度：</b>2007<br><b>关键词：</b>支持向量机 主成分分析 集成学习 特征选择 电机故障诊断 小样本学习
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">13</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">44%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">根据<span class="g-underline-text">大</span>数定理理论，<span class="g-underline-text">当</span>训练集<span class="g-underline-text">的</span>规模趋向于<span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>也<span class="g-underline-text">会</span>趋向于<span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">函数。虽然<span class="g-underline-text">当</span>样本空间中<span class="g-underline-text">的</span>样本数量趋于<span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span><span class="g-underline-text">会</span>在概率上趋近于<span class="g-underline-text">期望</span><span class="g-underline-text">风险</span></p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            ，有满足学习过程的本质目的并不是让经验风险无限逼近于期望风险，而是需要获得在经验风险最小化的原则下的某一最优函数厂，使得该函数趋近于使期望风险最小化时的<span class="g-font-color green">函数。虽然当样本空间中的样本数量趋于无穷大时，经验风险会在概率上趋近于期望风险</span>，以至于使得经验风险最小化的函数在一定程度上趋近于期望风险最小化的函数。但是当样本                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《数据驱动的短中期电力需求预测优化学习方法研究》<br><b>作者：</b>章政<br><b>分类号：</b>TM715<br><b>学科专业：</b>管理科学与工程<br><b>授予学位：</b>博士<br><b>导师姓名：</b>杨善林<br><b>学位授予单位：</b>合肥工业大学<br><b>学位年度：</b>2015<br><b>关键词：</b>电力网 需求预测 数据驱动 优化学习法
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">14</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">44%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">根据<span class="g-underline-text">大数</span>定理理论，当<span class="g-underline-text">训练</span><span class="g-underline-text">集</span><span class="g-underline-text">的</span><span class="g-underline-text">规模</span>趋向<span class="g-underline-text">于</span>无穷大时，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>也会趋向<span class="g-underline-text">于</span><span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">：由<span class="g-underline-text">大数</span>定律可以证明，随着<span class="g-underline-text">训练</span><span class="g-underline-text">集</span><span class="g-underline-text">规模</span><span class="g-underline-text">的</span>扩大，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>将逐渐收敛<span class="g-underline-text">于</span><span class="g-underline-text">期望</span><span class="g-underline-text">风险</span>更一般</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            ：由于多数情况下，概率分布函数P(z，，)无法预知，因此在整个样本空间的期望风险的估计也十分困难．而在训练集上，对误差的估计可以通过经验风险来实现，即<span class="g-font-color green">：由大数定律可以证明，随着训练集规模的扩大，经验风险将逐渐收敛于期望风险更一般</span>的，Vapnik与Chervonenkis证明，即对于区间[1，0)中的任取值q，学习器的期望风险以                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《一种SVM增量学习算法》<br><b>作者：</b>萧嵘 王继成 孙正兴 张福炎<br><b>作者单位：</b>南京大学软件新技术国家重点实验室南京大学计算机科学与技术系,南京,210093<br><b>参考文献：</b>6篇<br><b>被引次数：</b>23次（统计时间：2015年8月）<br><b>页码：</b>P152—P157<br><b>页数：</b>6页<br><b>分类号：</b>TP18<br><b>机标分类号：</b>TP3 TP1<br><b>基金项目：</b>国家自然科学基金(69903006,60073030);江苏省科技攻关项目(BE96017)<br><b>期刊名称：</b>《南京大学学报(自然科学版)》<br><b>出版时间：</b>2002年2期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>0469-5097<br><b>关键词：</b>支持向量机 分类 增量学习 机器学习
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">15</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">43%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">根据<span class="g-underline-text">大</span>数定理<span class="g-underline-text">理论</span>，<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>集<span class="g-underline-text">的</span>规模趋向于<span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span>也会趋向于期望<span class="g-underline-text">风险</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">是统计学习<span class="g-underline-text">理论</span><span class="g-underline-text">的</span>基础，指<span class="g-underline-text">当</span><span class="g-underline-text">训练</span>样本数目趋于<span class="g-underline-text">无穷</span><span class="g-underline-text">大</span><span class="g-underline-text">时</span>，<span class="g-underline-text">经验</span><span class="g-underline-text">风险</span><span class="g-underline-text">的</span>最优值能够收敛到</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            却往往丧失推广性。6.2.3函数集的学习性能和VC维【6-9]统计学习理论被认为是目前针对小样本统计估计和预测学习的最佳理论。关于学习一致性的结论<span class="g-font-color green">是统计学习理论的基础，指当训练样本数目趋于无穷大时，经验风险的最优值能够收敛到</span>真实风险的最优值.定理6.1对于有界的损失函数，经验风险最小化学习一致的充分必要                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《自适应单载波、多载波调制中信号盲检测技术研究》<br><b>作者：</b>韩钢<br><b>分类号：</b>TN911.23<br><b>学科专业：</b>通信与信息系统<br><b>授予学位：</b>博士<br><b>导师姓名：</b>李建东<br><b>学位授予单位：</b>西安电子科技大学<br><b>学位年度：</b>2003<br><b>关键词：</b>自适应单载波 自适应多载波 高阶累积量 调制方式盲检测 调制识别 支撑矢量机
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
            
                <!--语句修改建议-->
        <span id="modify_suggest"></span>
        <div id="advice">
            <div class="g-line-row"></div>
            <div class="paper-txt P30 PB0">
                <div class="paper-section">
                    <p class="g-font-s16 font-bold g-font-color green MB10">该句修改建议（重度相似，请全面修改）</p>
                    <span class="g-font-color green">根据<span class="g-font-color red"><span class="g-font-color red">大</span>数</span><span class="g-font-color red">定理</span>理论，当<span class="g-font-color red">训练</span><span class="g-font-color red">集</span>的规模<span class="g-font-color red">趋向</span>于<span class="g-font-color red">无穷</span><span class="g-font-color red">大</span><span class="g-font-color red">时</span>，<span class="g-font-color red">经验</span><span class="g-font-color red">风险</span>也会<span class="g-font-color red">趋向</span>于<span class="g-font-color red">期望</span><span class="g-font-color red">风险</span>。</span>
                    <div class="MT10">
                        <p class="font-bold">同义词：</p>
                        <ul class="local-source-detail">
                            <li class="g-font-color green"><span class="g-font-color red">定理：</span>定律</li><li class="g-font-color green"><span class="g-font-color red">经验：</span>履历 经历</li><li class="g-font-color green"><span class="g-font-color red">风险：</span>危害  为害</li><li class="g-font-color green"><span class="g-font-color red">无穷：</span>无限 无尽 无边 用不完</li><li class="g-font-color green"><span class="g-font-color red">趋向：</span>趋势  来头 系列化 主旋律</li><li class="g-font-color green"><span class="g-font-color red">训练：</span>教练 锻练</li>
                        </ul>

                    </div>
                </div>
            </div>
        </div>
            </div>
    <div class="back-to-top text-center">
        <a href="#gototop" class="font-bold g-font-color green">回到顶部</a>
    </div>
    <div class="paper-footer">
        <p>检测报告由<a href="http://www.paperpass.com/" target="_black">PaperPass</a>文献相似度检测系统生成</p>
        <p>Copyright © 2007-2020 PaperPass</p>
    </div>
</div>
</body>
<script type="text/javascript" src="../js/jquery.min.js"></script>
<script type="text/javascript" src="../js/Lib.js"></script>
<script type="text/javascript">
    (function(System,$){
        var tab = System.Paper.tab();
        var $advice = null;
        function run(){
            var i = 0;
            $advice.show();
            tab.call(this,{callback:function(){
                var $num = $(this).find('.chapter-num');
                if($num.length>0){
                    i++;
                    $num.text(i);
                }
            }});
            //没有内容时同时不显示该句修改建议
            if(0 === i){$advice.hide();}
        }
        $(function(){
            $advice = $('#advice');
            $(document).on('click','[tab-a="ul"] li',function(){
                run.call(this);
            });
            $(document).on('click','[tab-b="ul"] li',function(){
                run.call(this);
            });
        });
    })(Report,jQuery);


</script>
</html>
