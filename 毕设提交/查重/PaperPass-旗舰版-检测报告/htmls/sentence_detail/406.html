<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="">
    <meta name="description" content="">
    <title>详细报告语句详情</title>
    <link href="../css/bootstrap.min.css" rel="stylesheet" />
    <link href="../css/style.css" rel="stylesheet" />
    <style type="text/css">
        .content-tips .paper-section{margin-bottom:0;min-width:450px;}
    </style>
</head>
<body>
<span id="gototop"></span>
<div>
    <div class="paper-txt P30">
        <div class="paper-section" style="margin-bottom:0;">
            <div class="font-bold MT5">
                该句相似度：<span class="g-font-color orange similarNum">63%</span>
            </div>
            <div class="MT30">
                <p class="font-bold">您的语句：</p>
                <span>长短期记忆网络LSTM是循环神经网络的一个变体，可以有效地解决简单循环神经网络的梯度消失/爆炸问题。</span>
            </div>
        </div>
    </div>
    <div>
        <div class="tab-A">
            <ul class="tab-A-ul clearfix" tab-a="ul">
                                        <li class="active" data-id="学术期刊,学位论文,学术会议,书籍数据,互联网,自建库,all">
                            <span class="tab-text">综合</span>
                            <span class="tab-superscript">9</span>
                        </li>
                                    <li data-id="tab,学术期刊,学位论文,学术会议,书籍数据,自建库,local"
                                    >
                    <span class="tab-text">本地库</span>
                    <span class="tab-superscript">9</span>
                </li>
                                <li data-id="互联网,5">
                    <span class="tab-text">互联网</span>
                    <span class="tab-superscript">0</span>
                </li>
                            </ul>
        </div>
        <div class="none" tab="section" data-id="tab"
                    >
            <div class="tab-B clearfix">
                <div class="paper-section P30 PB0 clearfix" style="padding:30px 10px 0">
                <ul class="tab-B-ul pull-left clearfix" tab-b="ul">
                        <li class="active" data-id="tab,学术期刊,学位论文,学术会议,书籍数据,自建库,local">
                            <span class="tab-text">全部</span>
                            <span class="tab-superscript">9</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,学术期刊,1">
                            <span class="tab-text">期刊</span>
                            <span class="tab-superscript">3</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,学位论文,2">
                            <span class="tab-text">学位</span>
                            <span class="tab-superscript">6</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,学术会议,3">
                            <span class="tab-text">会议</span>
                            <span class="tab-superscript">0</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,书籍数据,4">
                            <span class="tab-text">图书</span>
                            <span class="tab-superscript">0</span>
                                                    </li>
                                            </ul>
                </div>
                <div class="g-line-row MT30 tab-pane-line"></div>
            </div>
        </div>
        <div class="content-tips">
            <div class="tab-content none" tab="section" data-id="1">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在期刊库共找出相似内容：<span>3</span>个                    <p>
                                        <div style="margin-top: 10px;">
                    <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>
                    </div>
                                    </div>
            </div>

            <div class="tab-content none" tab="section" data-id="2">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在学位库共找出相似内容：<span>6</span>个                    <p>
                                        <div style="margin-top: 10px;">
                    <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>                    </div>
                                    </div>
            </div>
            <div class="tab-content none" tab="section" data-id="3">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在会议库中没有找到与此句话相似的内容                    <p>
                                        <div style="margin-top: 10px;">
                                        </div>
                                    </div>
            </div>
            <div class="tab-content none" tab="section" data-id="4">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在图书库中没有找到与此句话相似的内容                    <p>
                                        <div style="margin-top: 10px;">
                                        </div>
                                    </div>
            </div>
            <div class="tab-content none" tab="section" data-id="5">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在互联网库中没有找到与此句话相似的内容                    <p>
                                        <div style="margin-top: 10px;">
                                        </div>
                                    </div>
            </div>
            <!-- 自建库 -->
            <div class="tab-content none" tab="section" data-id="6">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在自建库中没有找到与此句话相似的内容                    <p>
                                        <div style="margin-top: 10px;">
                                        </div>
                                    </div>
            </div>
                        <div class="tab-content" tab="section" data-id="all">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                                                在本地库和互联网库共找出相似内容：<span>9</span>个
                                            <p>
                                            <div style="margin-top: 10px;">
                    <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>

                    </div>
                                    </div>
            </div>
            <div class="tab-content none" tab="section" data-id="local">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在本地库共找出相似内容：<span>9</span>个                    <p>
                                        <div style="margin-top: 10px;">
                    <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>
                    </div>
                                    </div>
            </div>
        </div>



                <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">1</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">63%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange"><span class="g-underline-text">长</span>短期记忆<span class="g-underline-text">网络</span>LSTM<span class="g-underline-text">是</span><span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">一个</span><span class="g-underline-text">变体</span>，<span class="g-underline-text">可以</span><span class="g-underline-text">有效</span><span class="g-underline-text">地</span><span class="g-underline-text">解决</span>简单<span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">梯度</span><span class="g-underline-text">消失</span>/<span class="g-underline-text">爆炸</span><span class="g-underline-text">问题</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">长</span>短时记忆<span class="g-underline-text">神经</span><span class="g-underline-text">网络</span>，<span class="g-underline-text">是</span><span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">一个</span><span class="g-underline-text">变体</span>，<span class="g-underline-text">可以</span><span class="g-underline-text">有效</span><span class="g-underline-text">地</span><span class="g-underline-text">解决</span>一般RNN<span class="g-underline-text">的</span><span class="g-underline-text">梯度</span><span class="g-underline-text">爆炸</span>或<span class="g-underline-text">消失</span><span class="g-underline-text">问题</span>。图3</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            的事件特征周期将会变短，这将不利于NILM任务里对于双状态或多状态电器的识别检测，也就会削弱RNN网络的优势。故而本文不使用标准RNN，而使用其变体神经网络LSTM，也是RNN的一种。LSTM称为<span class="g-font-color green">长短时记忆神经网络，是循环神经网络的一个变体，可以有效地解决一般RNN的梯度爆炸或消失问题。图3</span>-6显示了LSTM的计算结构。LSTM结构的万方数据华中科技大学硕士学位论文关键是引入了一组记忆单元（MU                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于深度学习优化的非侵入式负荷监控算法研究》<br><b>作者：</b>李葱<br><b>学科专业：</b>信息与通信工程<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>戴彬<br><b>学位授予单位：</b>华中科技大学<br><b>学位年度：</b>2017
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">2</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">61%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">长短期记忆<span class="g-underline-text">网络</span>LSTM<span class="g-underline-text">是</span><span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">一个</span><span class="g-underline-text">变体</span>，<span class="g-underline-text">可以</span><span class="g-underline-text">有效</span><span class="g-underline-text">地</span>解决简单<span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">梯度</span><span class="g-underline-text">消失</span>/<span class="g-underline-text">爆炸</span><span class="g-underline-text">问题</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">，该<span class="g-underline-text">网络</span><span class="g-underline-text">是</span><span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">一个</span><span class="g-underline-text">有效</span><span class="g-underline-text">变体</span>，<span class="g-underline-text">可以</span><span class="g-underline-text">有效</span><span class="g-underline-text">地</span>缓解<span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">梯度</span><span class="g-underline-text">爆炸</span>或<span class="g-underline-text">梯度</span><span class="g-underline-text">消失</span><span class="g-underline-text">的</span><span class="g-underline-text">问题</span>。</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            时间间隔较大时，会导致更新梯度过大或过小，以至于产生梯度爆炸或梯度消失问题，导致循环神经网络只能学习序列中较短周期的依赖关系。为了解决以上问题，提高循环神经网络长周期长序列的依赖关系的学<span class="g-font-color green">，该网络是循环神经网络的一个有效变体，可以有效地缓解循环神经网络梯度爆炸或梯度消失的问题。</span>长短时记忆神经网络与传统循环神经网络相比，关键的不同之处在于：长短时记忆神经网络引入了门机制(GatingMechanism                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于深度卷积神经网络的视觉物体识别算法》<br><b>作者：</b>孙满利<br><b>学科专业：</b>电子与通信工程<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>庞建新<br><b>学位授予单位：</b>天津大学<br><b>学位年度：</b>2016
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">3</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">50%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">长<span class="g-underline-text">短期</span><span class="g-underline-text">记忆</span><span class="g-underline-text">网络</span>LSTM<span class="g-underline-text">是</span><span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span>一个<span class="g-underline-text">变体</span>，<span class="g-underline-text">可以</span><span class="g-underline-text">有效</span><span class="g-underline-text">地</span><span class="g-underline-text">解决</span>简单<span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span>梯度消失/爆炸<span class="g-underline-text">问题</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">短期</span><span class="g-underline-text">记忆</span>单元LSTM[31]，<span class="g-underline-text">是</span>一种<span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">变体</span>，<span class="g-underline-text">可以</span><span class="g-underline-text">有效</span><span class="g-underline-text">地</span><span class="g-underline-text">解决</span>长期依赖引发<span class="g-underline-text">的</span>一系列<span class="g-underline-text">问题</span></p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            反向传播的过程中会引入指数项，如果指数项底的取值小于1的情况下，会引起梯度消失的问题；如果其值大于1时，就会引起梯度爆炸问题。由德国学者SeppHocllreiter和Jue唱enSchmidHuber提出的长<span class="g-font-color green">短期记忆单元LSTM[31]，是一种循环神经网络的变体，可以有效地解决长期依赖引发的一系列问题</span>。传统的循环神经网络中只包含一个隐藏层的状态，当时问序列过长时无法完整保存长期的状态信息，                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于多特征融合的视频分类方法研究》<br><b>作者：</b>冯朝阳<br><b>学科专业：</b>软件工程<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>邢薇薇<br><b>学位授予单位：</b>北京交通大学<br><b>学位年度：</b>2018
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">4</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">49%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">长短期记忆<span class="g-underline-text">网络</span>LSTM<span class="g-underline-text">是</span><span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span>一个变体，<span class="g-underline-text">可以</span>有效地解决简单<span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">梯度</span><span class="g-underline-text">消失</span>/爆炸<span class="g-underline-text">问题</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">，LSTM<span class="g-underline-text">网络</span>应运而生。LSTM<span class="g-underline-text">网络</span><span class="g-underline-text">是</span>一种特殊<span class="g-underline-text">的</span><span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span>类型，<span class="g-underline-text">可以</span>克服普通<span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">梯度</span><span class="g-underline-text">消失</span><span class="g-underline-text">的</span><span class="g-underline-text">问题</span>，</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            为输入序列在时刻t的值。在应用误差反向传播算法后，梯度是一系列小于1的导数连乘的形式，随着t的增大，很快会接近于零，导致无法有效训练网络权重【40，4¨。为解决这个难题<span class="g-font-color green">，LSTM网络应运而生。LSTM网络是一种特殊的循环神经网络类型，可以克服普通循环神经网络梯度消失的问题，</span>它在语音识另，lt421，文本生成【431，图片描述Ⅲ】等具有序列相关性的很多问题上都取得了                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于人工神经网络的短期电力负荷预测研究》<br><b>作者：</b>程宇也<br><b>分类号：</b>TP183<br><b>学科专业：</b>电气工程<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>包哲静<br><b>学位授予单位：</b>浙江大学<br><b>学位年度：</b>2017<br><b>关键词：</b>电力系统 负荷预测 人工神经网络 预测模型
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">5</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">49%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">长短期记忆<span class="g-underline-text">网络</span>LSTM<span class="g-underline-text">是</span><span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">一个</span>变体，可以有效地解决简单<span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span>梯度消失/爆炸问题。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span>[11]<span class="g-underline-text">是</span><span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">一个</span>变种。双向<span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span>与标准<span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span>区别在于，标准</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            bo分别表示记忆块、输入门单元、遗忘门单元和输出门单元的偏置;☉表示阿达马积;σ表万方数据示sigmoid激活函数;tan表示tan激活函数。1.2.2双向长短时记忆循环神经网络模型双向循环<span class="g-font-color green">神经网络[11]是循环神经网络的一个变种。双向循环神经网络与标准循环神经网络的区别在于，标准</span>循环神经网络在t时刻的状态只与过去时刻(t-1，t-2，…，0)的状态有关                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于双向长短时神经网络的水量预测方法研究》<br><b>作者：</b>郭冠呈 刘书明 李俊禹 周韧 朱晓耘<br><b>作者单位：</b>清华大学环境学院 饮用水安全教研所,北京,100084；常州通用自来水有限公司,常州,213003<br><b>参考文献：</b>11篇<br><b>页码：</b>P123—P126<br><b>页数：</b>4页<br><b>基金项目：</b>国家水体污染控制与治理科技重大专项(2017ZX07201002)<br><b>期刊名称：</b>《给水排水》<br><b>出版时间：</b>2018年3期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>1002-8471<br><b>关键词：</b>水量预测 深度学习 长短时记忆单元 人工神经网络<br><b>摘要：</b>短期需水量预测是开展城镇供水管网智能调度和基于流量的漏失在线预警的基础,受限于需水量的非线性变化,传统模型的预测精度和稳定性较差,尤其是对于15 min 间隔的需水量预测.为解决此问题,提出了一种利用深度学习的水量预测方法,建立了双向长短时记忆循环神经网络模型预测常州市某DMA入口15 min的水量.结果表明,双向长短时记忆循环神经网络模型的预测效果优于传统人工神经网络模型,能够有效提升水量预测模型的精度与稳定性.
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">6</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">44%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange"><span class="g-underline-text">长</span><span class="g-underline-text">短期</span><span class="g-underline-text">记忆</span><span class="g-underline-text">网络</span>LSTM是循环<span class="g-underline-text">神经</span><span class="g-underline-text">网络</span>的一个变体，可以有效地解决简单循环<span class="g-underline-text">神经</span><span class="g-underline-text">网络</span>的梯度消失/爆炸问题。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">长</span><span class="g-underline-text">短期</span><span class="g-underline-text">记忆</span><span class="g-underline-text">长</span><span class="g-underline-text">网络</span>影象<span class="g-underline-text">神经</span><span class="g-underline-text">网络</span>层<span class="g-underline-text">神经</span><span class="g-underline-text">网络</span>层<span class="g-underline-text">神经</span><span class="g-underline-text">网络</span>层<span class="g-underline-text">神经</span>收集层||||||||、、</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            卷积神经×    3D卷积神经3网络卷积网络收集网络收集网络收集层收集层3D卷积神经3D卷积神经3D卷积神经3网络卷积网络收集网络收集网络收集层收集记忆长短期记忆长短期记忆<span class="g-font-color green">长短期记忆长网络影象神经网络层神经网络层神经网络层神经收集层||||||||、、</span>、、心么二网络全连接收集层Sol，max分类层万方数据3DCNNs与LSTMs在行为识别中的组合及其                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《3D CNNs与LSTMs在行为识别中的组合及其应用》<br><b>作者：</b>秦阳 莫凌飞 郭文科 李钒<br><b>作者单位：</b>东南大学仪器科学与工程学院,江苏南京,210096<br><b>参考文献：</b>14篇<br><b>页码：</b>P28—P32<br><b>页数：</b>5页<br><b>分类号：</b>TP183<br><b>基金项目：</b>中央高校基本科研业务费专项(2242014R30021)<br><b>期刊名称：</b>《测控技术》<br><b>出版时间：</b>2017年2期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>1000-8829<br><b>关键词：</b>行为识别 深度学习 神经网络 模式识别<br><b>摘要：</b>基于机器视觉的人体运动识别在视频监控、虚拟现实、医疗护理等诸多领域发挥着重要的作用.结合深度学习中的三维卷积神经网络和长短期记忆神经网络,提出一种融合模型,并与另外两种行为识别模型——长效递归卷积网络和时空域卷积网络,进行了对比,利用公开的KTH数据集,进行了实验测试.实验表明,提出的融合模型与长效递归卷积网络和时空域卷积网络相比,对于人体行为图像或视频数据集的学习效果明显,论证了模型的泛化性能和鲁棒性.
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">7</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">43%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange"><span class="g-underline-text">长</span><span class="g-underline-text">短期</span><span class="g-underline-text">记忆</span><span class="g-underline-text">网络</span>LSTM<span class="g-underline-text">是</span><span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span>一个变体，可以有效地<span class="g-underline-text">解决</span>简单<span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">梯度</span><span class="g-underline-text">消失</span>/<span class="g-underline-text">爆炸</span><span class="g-underline-text">问题</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">长</span><span class="g-underline-text">短期</span><span class="g-underline-text">记忆</span>模型，<span class="g-underline-text">是</span>为<span class="g-underline-text">解决</span><span class="g-underline-text">循环</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">长</span>距离传输所导致<span class="g-underline-text">的</span><span class="g-underline-text">梯度</span><span class="g-underline-text">爆炸</span>或者<span class="g-underline-text">梯度</span><span class="g-underline-text">消失</span><span class="g-underline-text">的</span><span class="g-underline-text">问题</span>。<span class="g-underline-text">长</span><span class="g-underline-text">短期</span><span class="g-underline-text">记忆</span></p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            的状态可以通过式(7)表示，其中，h；是第l层的t时刻的状态。当z一1时，状态剜一1为T，网络的训练方法与循环神经网络的方法相同。3．4长短期记忆模型<span class="g-font-color green">长短期记忆模型，是为解决循环神经网络长距离传输所导致的梯度爆炸或者梯度消失的问题。长短期记忆</span>模型在原有的循环神经网络的基础上，添加了输入门，输出门，遗忘门和中心记忆单元，中心记忆单元                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于深度学习的藏文分词方法》<br><b>作者：</b>李博涵 刘汇丹 龙从军 吴健<br><b>作者单位：</b>中国科学院软件研究所,北京100190；中国科学院大学计算机与控制学院,北京100049；中国科学院软件研究所,北京,100190；中国社会科学院民族学与人类学研究所,北京100081<br><b>参考文献：</b>15篇<br><b>页码：</b>P194—P198<br><b>页数：</b>5页<br><b>分类号：</b>TP391<br><b>基金项目：</b>国家自然科学基金项目(61303165、61540057、61132009);青海省自然科学基金项目(2016-ZJ-Y04、2016-ZJ-740);国家语委重点基金项目(ZDI135-17)<br><b>期刊名称：</b>《计算机工程与设计》<br><b>出版时间：</b>2018年1期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>1000-7024<br><b>关键词：</b>深度学习 藏文分词 循环神经网络 长短期记忆 编码器-标注器<br><b>摘要：</b>重点研究将深度学习技术应用于藏文分词任务,采用多种深度神经网络模型,包括循环神经网络(RNN)、双向循环神经网络(BiRNN)、层叠循环神经网络(StackedRNN)、长短期记忆模型(LSTM)和编码器-标注器长短期记忆模型(Encoder-Labeler LSTM).多种模型在以法律文本、政府公文、新闻为主的分词语料中进行实验,实验数据表明,编码器-标注器长短期记忆模型得到的分词结果最好,分词准确率可以达到92.96％,召回率为93.30％,F值为93.13％.
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">8</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">43%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange"><span class="g-underline-text">长</span><span class="g-underline-text">短期</span><span class="g-underline-text">记忆</span><span class="g-underline-text">网络</span>LSTM是循环<span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span>一个变体，可以有效<span class="g-underline-text">地</span><span class="g-underline-text">解决</span>简单循环<span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">梯度</span><span class="g-underline-text">消失</span>/<span class="g-underline-text">爆炸</span><span class="g-underline-text">问题</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">长</span><span class="g-underline-text">短期</span><span class="g-underline-text">记忆</span><span class="g-underline-text">网络</span>模型能够更好<span class="g-underline-text">地</span><span class="g-underline-text">记忆</span><span class="g-underline-text">长</span>期信息，而且还能够<span class="g-underline-text">解决</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span>训练中头疼<span class="g-underline-text">的</span><span class="g-underline-text">梯度</span><span class="g-underline-text">消失</span>和<span class="g-underline-text">梯度</span><span class="g-underline-text">爆炸</span><span class="g-underline-text">问题</span>。</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            量表示。两个子网络会在模型的混合层来结合相互信息，最后通过softmax取样出下一个单词。Vinyals等人[15]使用了一种长短期记忆网络模型（LSTM）来处理描述语句部分，相比于循环神经网络模型，<span class="g-font-color green">长短期记忆网络模型能够更好地记忆长期信息，而且还能够解决神经网络训练中头疼的梯度消失和梯度爆炸问题。</span>而图像部分，他们仍使用卷积神经网络来处理，但是相对于自己设计一种卷积神经网络，他们使用了曾在                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《图像描述文本自动生成方法研究》<br><b>作者：</b>申永飞<br><b>分类号：</b>TP391.41<br><b>学科专业：</b>计算机科学与技术<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>李季<br><b>学位授予单位：</b>重庆大学<br><b>学位年度：</b>2017<br><b>关键词：</b>图像描述 自动生成 文本句子 集束搜索 记忆网络
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">9</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">40%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange"><span class="g-underline-text">长</span><span class="g-underline-text">短期</span><span class="g-underline-text">记忆</span><span class="g-underline-text">网络</span>LSTM是循环<span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span>一个变体，可以<span class="g-underline-text">有效</span>地解决<span class="g-underline-text">简单</span>循环<span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span>梯度消失/爆炸问题。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">，<span class="g-underline-text">长</span><span class="g-underline-text">短期</span><span class="g-underline-text">记忆</span><span class="g-underline-text">神经</span><span class="g-underline-text">网络</span>（LongShort-TermMemory，LSTM）比<span class="g-underline-text">简单</span><span class="g-underline-text">的</span>递归<span class="g-underline-text">神经</span><span class="g-underline-text">网络</span>RNN更加<span class="g-underline-text">有效</span>。作为递归<span class="g-underline-text">神经</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span></p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            ，⊙是元素对元同时，新的记忆单元的值和输出值由公式4-2给出：其中，万方数据哈尔滨工业大学工学硕士学位论文•xt是记忆单元在时刻t的输入，bf，bc和bo为偏置向量已经证明<span class="g-font-color green">，长短期记忆神经网络（LongShort-TermMemory，LSTM）比简单的递归神经网络RNN更加有效。作为递归神经网络的</span>一种变形，长短期记忆神经网络同样可以被展开（如图4-3），并且可以多层叠加（stackedLSTM），形成                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于深度学习的自然语言句法分析研究》<br><b>作者：</b>周青宇<br><b>分类号：</b>TP391.1<br><b>学科专业：</b>计算机科学与技术<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>赵铁军<br><b>学位授予单位：</b>哈尔滨工业大学<br><b>学位年度：</b>2016<br><b>关键词：</b>自然语言处理 依存句法分析 深度学习 神经网络
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
            
                <!--语句修改建议-->
        <span id="modify_suggest"></span>
        <div id="advice">
            <div class="g-line-row"></div>
            <div class="paper-txt P30 PB0">
                <div class="paper-section">
                    <p class="g-font-s16 font-bold g-font-color green MB10">该句修改建议（轻度相似，请酌情修改）</p>
                    <span class="g-font-color green"><span class="g-font-color red">长</span>短期记忆<span class="g-font-color red">网络</span>LSTM是<span class="g-font-color red">循环</span><span class="g-font-color red">神经</span><span class="g-font-color red">网络</span>的<span class="g-font-color red">一个</span><span class="g-font-color red">变体</span>，可以<span class="g-font-color red">有效</span><span class="g-font-color red">地</span><span class="g-font-color red">解决</span>简单<span class="g-font-color red">循环</span><span class="g-font-color red">神经</span><span class="g-font-color red">网络</span>的<span class="g-font-color red">梯度</span><span class="g-font-color red">消失</span>/<span class="g-font-color red">爆炸</span><span class="g-font-color red">问题</span>。</span>
                    <div class="MT10">
                        <p class="font-bold">同义词：</p>
                        <ul class="local-source-detail">
                            <li class="g-font-color green"><span class="g-font-color red">有效：</span>有用</li><li class="g-font-color green"><span class="g-font-color red">循环：</span>轮回 大 巡回</li><li class="g-font-color green"><span class="g-font-color red">消失：</span>消散 消逝 磨灭</li><li class="g-font-color green"><span class="g-font-color red">问题：</span>标题  题目</li><li class="g-font-color green"><span class="g-font-color red">网络：</span>收集</li><li class="g-font-color green"><span class="g-font-color red">爆炸：</span>爆裂 放炮</li><li class="g-font-color green"><span class="g-font-color red">解决：</span>办理 打点 管理  操办</li>
                        </ul>

                    </div>
                </div>
            </div>
        </div>
            </div>
    <div class="back-to-top text-center">
        <a href="#gototop" class="font-bold g-font-color green">回到顶部</a>
    </div>
    <div class="paper-footer">
        <p>检测报告由<a href="http://www.paperpass.com/" target="_black">PaperPass</a>文献相似度检测系统生成</p>
        <p>Copyright © 2007-2020 PaperPass</p>
    </div>
</div>
</body>
<script type="text/javascript" src="../js/jquery.min.js"></script>
<script type="text/javascript" src="../js/Lib.js"></script>
<script type="text/javascript">
    (function(System,$){
        var tab = System.Paper.tab();
        var $advice = null;
        function run(){
            var i = 0;
            $advice.show();
            tab.call(this,{callback:function(){
                var $num = $(this).find('.chapter-num');
                if($num.length>0){
                    i++;
                    $num.text(i);
                }
            }});
            //没有内容时同时不显示该句修改建议
            if(0 === i){$advice.hide();}
        }
        $(function(){
            $advice = $('#advice');
            $(document).on('click','[tab-a="ul"] li',function(){
                run.call(this);
            });
            $(document).on('click','[tab-b="ul"] li',function(){
                run.call(this);
            });
        });
    })(Report,jQuery);


</script>
</html>
