<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="">
    <meta name="description" content="">
    <title>详细报告语句详情</title>
    <link href="../css/bootstrap.min.css" rel="stylesheet" />
    <link href="../css/style.css" rel="stylesheet" />
    <style type="text/css">
        .content-tips .paper-section{margin-bottom:0;min-width:450px;}
    </style>
</head>
<body>
<span id="gototop"></span>
<div>
    <div class="paper-txt P30">
        <div class="paper-section" style="margin-bottom:0;">
            <div class="font-bold MT5">
                该句相似度：<span class="g-font-color red similarNum">94%</span>
            </div>
            <div class="MT30">
                <p class="font-bold">您的语句：</p>
                <span>当网络的层数很深时，梯度就会不停衰减，甚至消失，使得整个网络很难训练。</span>
            </div>
        </div>
    </div>
    <div>
        <div class="tab-A">
            <ul class="tab-A-ul clearfix" tab-a="ul">
                                        <li class="active" data-id="学术期刊,学位论文,学术会议,书籍数据,互联网,自建库,all">
                            <span class="tab-text">综合</span>
                            <span class="tab-superscript">6</span>
                        </li>
                                    <li data-id="tab,学术期刊,学位论文,学术会议,书籍数据,自建库,local"
                                    >
                    <span class="tab-text">本地库</span>
                    <span class="tab-superscript">2</span>
                </li>
                                <li data-id="互联网,5">
                    <span class="tab-text">互联网</span>
                    <span class="tab-superscript">4</span>
                </li>
                            </ul>
        </div>
        <div class="none" tab="section" data-id="tab"
                    >
            <div class="tab-B clearfix">
                <div class="paper-section P30 PB0 clearfix" style="padding:30px 10px 0">
                <ul class="tab-B-ul pull-left clearfix" tab-b="ul">
                        <li class="active" data-id="tab,学术期刊,学位论文,学术会议,书籍数据,自建库,local">
                            <span class="tab-text">全部</span>
                            <span class="tab-superscript">2</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,学术期刊,1">
                            <span class="tab-text">期刊</span>
                            <span class="tab-superscript">0</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,学位论文,2">
                            <span class="tab-text">学位</span>
                            <span class="tab-superscript">2</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,学术会议,3">
                            <span class="tab-text">会议</span>
                            <span class="tab-superscript">0</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,书籍数据,4">
                            <span class="tab-text">图书</span>
                            <span class="tab-superscript">0</span>
                                                    </li>
                                            </ul>
                </div>
                <div class="g-line-row MT30 tab-pane-line"></div>
            </div>
        </div>
        <div class="content-tips">
            <div class="tab-content none" tab="section" data-id="1">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在期刊库中没有找到与此句话相似的内容                    <p>
                                        <div style="margin-top: 10px;">
                    
                    </div>
                                    </div>
            </div>

            <div class="tab-content none" tab="section" data-id="2">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在学位库共找出相似内容：<span>2</span>个                    <p>
                                        <div style="margin-top: 10px;">
                    <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>                    </div>
                                    </div>
            </div>
            <div class="tab-content none" tab="section" data-id="3">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在会议库中没有找到与此句话相似的内容                    <p>
                                        <div style="margin-top: 10px;">
                                        </div>
                                    </div>
            </div>
            <div class="tab-content none" tab="section" data-id="4">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在图书库中没有找到与此句话相似的内容                    <p>
                                        <div style="margin-top: 10px;">
                                        </div>
                                    </div>
            </div>
            <div class="tab-content none" tab="section" data-id="5">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在互联网库共找出相似内容：<span>4</span>个                    <p>
                                        <div style="margin-top: 10px;">
                    <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>                    </div>
                                    </div>
            </div>
            <!-- 自建库 -->
            <div class="tab-content none" tab="section" data-id="6">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在自建库中没有找到与此句话相似的内容                    <p>
                                        <div style="margin-top: 10px;">
                                        </div>
                                    </div>
            </div>
                        <div class="tab-content" tab="section" data-id="all">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                                                在本地库和互联网库共找出相似内容：<span>6</span>个
                                            <p>
                                            <div style="margin-top: 10px;">
                    <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>

                    </div>
                                    </div>
            </div>
            <div class="tab-content none" tab="section" data-id="local">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green">
                        在本地库共找出相似内容：<span>2</span>个                    <p>
                                        <div style="margin-top: 10px;">
                    <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>
                    </div>
                                    </div>
            </div>
        </div>



                <div class="tab-content" tab="section" data-id="互联网">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">1</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color red similarNum">94%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color red"><span class="g-underline-text">当</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">层数</span><span class="g-underline-text">很</span><span class="g-underline-text">深</span><span class="g-underline-text">时</span>，<span class="g-underline-text">梯度</span><span class="g-underline-text">就</span><span class="g-underline-text">会</span><span class="g-underline-text">不停</span><span class="g-underline-text">衰减</span>，<span class="g-underline-text">甚至</span><span class="g-underline-text">消失</span>，<span class="g-underline-text">使得</span><span class="g-underline-text">整个</span><span class="g-underline-text">网络</span><span class="g-underline-text">很</span><span class="g-underline-text">难</span><span class="g-underline-text">训练</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">当</span><span class="g-underline-text">网络</span><span class="g-underline-text">层数</span><span class="g-underline-text">很</span><span class="g-underline-text">深</span><span class="g-underline-text">时</span>，<span class="g-underline-text">梯度</span><span class="g-underline-text">就</span><span class="g-underline-text">会</span><span class="g-underline-text">不停</span><span class="g-underline-text">的</span><span class="g-underline-text">衰减</span>，<span class="g-underline-text">甚至</span><span class="g-underline-text">消失</span>，<span class="g-underline-text">使得</span><span class="g-underline-text">整个</span><span class="g-underline-text">网络</span><span class="g-underline-text">很</span><span class="g-underline-text">难</span><span class="g-underline-text">训练</span>。</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            <span class="g-font-color green">当网络层数很深时，梯度就会不停的衰减，甚至消失，使得整个网络很难训练。</span>这就是所谓的梯度消失问题。减轻梯度消失问题的一个方法是使用线性激活函数(例如rectifler                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（互联网）：</p>
                            <div class="local-source-detail">
                                <b>标题：</b>深度学习总结笔记（二） - zgyggy的博客 - CSDN博客<br/><a href='https://blog.csdn.net/zgyggy/article/details/78363713?utm_source=blogxgwz8' target='_blank'>https://blog.csdn.net/zgyggy/article/details/78363713?utm_source=blogxgwz8</a>
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="互联网">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">2</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color red similarNum">94%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color red"><span class="g-underline-text">当</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">层数</span><span class="g-underline-text">很</span><span class="g-underline-text">深</span><span class="g-underline-text">时</span>，<span class="g-underline-text">梯度</span><span class="g-underline-text">就</span><span class="g-underline-text">会</span><span class="g-underline-text">不停</span><span class="g-underline-text">衰减</span>，<span class="g-underline-text">甚至</span><span class="g-underline-text">消失</span>，<span class="g-underline-text">使得</span><span class="g-underline-text">整个</span><span class="g-underline-text">网络</span><span class="g-underline-text">很</span><span class="g-underline-text">难</span><span class="g-underline-text">训练</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">当</span><span class="g-underline-text">网络</span><span class="g-underline-text">层数</span><span class="g-underline-text">很</span><span class="g-underline-text">深</span><span class="g-underline-text">时</span>，<span class="g-underline-text">梯度</span><span class="g-underline-text">就</span><span class="g-underline-text">会</span><span class="g-underline-text">不停</span><span class="g-underline-text">的</span><span class="g-underline-text">衰减</span>，<span class="g-underline-text">甚至</span><span class="g-underline-text">消失</span>，<span class="g-underline-text">使得</span><span class="g-underline-text">整个</span><span class="g-underline-text">网络</span><span class="g-underline-text">很</span><span class="g-underline-text">难</span><span class="g-underline-text">训练</span>。</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            激活函数的导数。我们可以看到，sigmoid型函数导数的值域都小于1。并且由于sigmoid型函数的饱和性，饱和区的导数更是接近于0。这样，误差经过每一层传递都会不断衰减。<span class="g-font-color green">当网络层数很深时，梯度就会不停的衰减，甚至消失，使得整个网络很难训练。</span>这就是所谓的梯度消失问题（VanishingGradientProblem），也叫梯度弥散问题。在深层神经网络中，减轻                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（互联网）：</p>
                            <div class="local-source-detail">
                                <b>标题：</b> 深度学习最精炼中文讲义 前馈与卷积神经网络详解，复旦邱锡鹏老师《神经网络与深度学习》报告分享02（附报告pdf下载） - 云+社区 - 腾讯云<br/><a href='https://cloud.tencent.com/developer/article/1089966' target='_blank'>https://cloud.tencent.com/developer/article/1089966</a>
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">3</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color red similarNum">91%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color red"><span class="g-underline-text">当</span><span class="g-underline-text">网络</span>的<span class="g-underline-text">层数</span><span class="g-underline-text">很</span><span class="g-underline-text">深</span><span class="g-underline-text">时</span>，<span class="g-underline-text">梯度</span>就<span class="g-underline-text">会</span>不停<span class="g-underline-text">衰减</span>，<span class="g-underline-text">甚至</span><span class="g-underline-text">消失</span>，<span class="g-underline-text">使得</span><span class="g-underline-text">整个</span><span class="g-underline-text">网络</span><span class="g-underline-text">很</span><span class="g-underline-text">难</span><span class="g-underline-text">训练</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">当</span><span class="g-underline-text">网络</span><span class="g-underline-text">层数</span><span class="g-underline-text">很</span><span class="g-underline-text">深</span><span class="g-underline-text">时</span>，<span class="g-underline-text">梯度</span><span class="g-underline-text">会</span>不断<span class="g-underline-text">衰减</span>，<span class="g-underline-text">甚至</span><span class="g-underline-text">消失</span>，这<span class="g-underline-text">使得</span><span class="g-underline-text">整个</span><span class="g-underline-text">网络</span><span class="g-underline-text">很</span><span class="g-underline-text">难</span><span class="g-underline-text">训练</span>。这</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            理工大学硕士学位论文CBIR中特征提取技术的比较研究鲁棒性。5．2．5梯度计算当我们使用sigmoid型函数时，由于其倒数值都小于1，这样误差经过每一层传递时都会不断衰减。<span class="g-font-color green">当网络层数很深时，梯度会不断衰减，甚至消失，这使得整个网络很难训练。这</span>就是所谓的梯度消失问题。首先，假定卷积层层数为，，子采样层层数是l+1层                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《CBIR中特征提取技术的比较研究》<br><b>作者：</b>吴强<br><b>分类号：</b>TP391.41<br><b>学科专业：</b>电子与通信工程<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>黄文清<br><b>学位授予单位：</b>浙江理工大学<br><b>学位年度：</b>2016<br><b>关键词：</b>图像检索 特征提取 空间颜色 灰度共生矩阵 哈希算法 卷积神经网络
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="互联网">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">4</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color red similarNum">86%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color red"><span class="g-underline-text">当</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">层数</span><span class="g-underline-text">很</span><span class="g-underline-text">深</span><span class="g-underline-text">时</span>，<span class="g-underline-text">梯度</span><span class="g-underline-text">就</span><span class="g-underline-text">会</span><span class="g-underline-text">不停</span><span class="g-underline-text">衰减</span>，<span class="g-underline-text">甚至</span><span class="g-underline-text">消失</span>，<span class="g-underline-text">使得</span><span class="g-underline-text">整个</span><span class="g-underline-text">网络</span><span class="g-underline-text">很</span><span class="g-underline-text">难</span>训练。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">当</span><span class="g-underline-text">网络</span><span class="g-underline-text">层数</span><span class="g-underline-text">很</span><span class="g-underline-text">深</span><span class="g-underline-text">时</span>，<span class="g-underline-text">梯度</span><span class="g-underline-text">就</span><span class="g-underline-text">会</span><span class="g-underline-text">不停</span><span class="g-underline-text">的</span><span class="g-underline-text">衰减</span>，<span class="g-underline-text">甚至</span><span class="g-underline-text">消失</span>，<span class="g-underline-text">使得</span><span class="g-underline-text">整个</span><span class="g-underline-text">网络</span><span class="g-underline-text">很</span><span class="g-underline-text">难</span></p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            <span class="g-font-color green">当网络层数很深时，梯度就会不停的衰减，甚至消失，使得整个网络很难</span>                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（互联网）：</p>
                            <div class="local-source-detail">
                                <b>标题：</b>nndl 读书笔记 第4章 前馈神经网络 - 简书<br/><a href='https://www.jianshu.com/p/4b6d264351c7' target='_blank'>https://www.jianshu.com/p/4b6d264351c7</a>
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="互联网">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">5</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color red similarNum">85%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color red"><span class="g-underline-text">当</span><span class="g-underline-text">网络</span>的<span class="g-underline-text">层数</span><span class="g-underline-text">很</span><span class="g-underline-text">深</span><span class="g-underline-text">时</span>，<span class="g-underline-text">梯度</span><span class="g-underline-text">就</span><span class="g-underline-text">会</span>不停<span class="g-underline-text">衰减</span>，<span class="g-underline-text">甚至</span><span class="g-underline-text">消失</span>，<span class="g-underline-text">使得</span><span class="g-underline-text">整个</span><span class="g-underline-text">网络</span><span class="g-underline-text">很</span>难<span class="g-underline-text">训练</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">当</span><span class="g-underline-text">网络</span><span class="g-underline-text">层数</span><span class="g-underline-text">很</span><span class="g-underline-text">深</span><span class="g-underline-text">时</span>，<span class="g-underline-text">梯度</span><span class="g-underline-text">就</span><span class="g-underline-text">会</span>不断<span class="g-underline-text">衰减</span>，<span class="g-underline-text">甚至</span><span class="g-underline-text">消失</span>，<span class="g-underline-text">使得</span><span class="g-underline-text">整个</span><span class="g-underline-text">网络</span><span class="g-underline-text">训练</span>难度加大。这</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            激活函数的导数。当我们使用sigimod型函数时，他们导数的值域都小于或者等于1。由于sigimod函数的饱和性，饱和区的导数更接近于0。这样，误差经过每一层都会衰减，<span class="g-font-color green">当网络层数很深时，梯度就会不断衰减，甚至消失，使得整个网络训练难度加大。这</span>就是梯度消失问题。正是由于这两个问题，让神经网络的参数学习比线性模型更加困难。在深度                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（互联网）：</p>
                            <div class="local-source-detail">
                                <b>标题：</b>神经网络及反向传播算法_神经网络，网络，算法_Mikow的博客-CSDN博客<br/><a href='https://blog.csdn.net/Mikow/article/details/106172805' target='_blank'>https://blog.csdn.net/Mikow/article/details/106172805</a>
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">6</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">57%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange"><span class="g-underline-text">当</span><span class="g-underline-text">网络</span><span class="g-underline-text">的</span><span class="g-underline-text">层数</span>很深时，梯度就<span class="g-underline-text">会</span>不停衰减，<span class="g-underline-text">甚至</span><span class="g-underline-text">消失</span>，<span class="g-underline-text">使得</span>整个<span class="g-underline-text">网络</span>很难<span class="g-underline-text">训练</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">。<span class="g-underline-text">当</span><span class="g-underline-text">网络</span><span class="g-underline-text">层数</span>较多时，残差<span class="g-underline-text">会</span>被不断<span class="g-underline-text">的</span>削弱<span class="g-underline-text">甚至</span><span class="g-underline-text">消失</span>，<span class="g-underline-text">使得</span><span class="g-underline-text">网络</span>难以<span class="g-underline-text">训练</span>。因此，</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            。神经网络在反向传播过程中需要对激活函数求导，那么Sigmoid型函数导数如下所示，可以看出，sigmoid型函数导数的最大值都小于1。那么残差在传递过程中会逐层衰减<span class="g-font-color green">。当网络层数较多时，残差会被不断的削弱甚至消失，使得网络难以训练。因此，</span>本文采用另一类的非线性激活函数，rectifier函数[56]。该函数定义为：rectifier函数被认为                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《复杂自然环境下车牌识别算法研究》<br><b>作者：</b>赵成龙<br><b>学科专业：</b>仪器科学与技术<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>朱文兴<br><b>学位授予单位：</b>山东大学<br><b>学位年度：</b>2017
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
            
                <!--语句修改建议-->
        <span id="modify_suggest"></span>
        <div id="advice">
            <div class="g-line-row"></div>
            <div class="paper-txt P30 PB0">
                <div class="paper-section">
                    <p class="g-font-s16 font-bold g-font-color green MB10">该句修改建议（重度相似，请全面修改）</p>
                    <span class="g-font-color green">当<span class="g-font-color red">网络</span>的<span class="g-font-color red">层数</span>很<span class="g-font-color red">深</span><span class="g-font-color red">时</span>，<span class="g-font-color red">梯度</span><span class="g-font-color red">就</span><span class="g-font-color red">会</span><span class="g-font-color red">不停</span><span class="g-font-color red">衰减</span>，甚至<span class="g-font-color red">消失</span>，<span class="g-font-color red">使得</span><span class="g-font-color red">整个</span><span class="g-font-color red">网络</span>很<span class="g-font-color red">难</span><span class="g-font-color red">训练</span>。</span>
                    <div class="MT10">
                        <p class="font-bold">同义词：</p>
                        <ul class="local-source-detail">
                            <li class="g-font-color green"><span class="g-font-color red">训练：</span>教练 锻练</li><li class="g-font-color green"><span class="g-font-color red">不停：</span>不断 不竭 不绝</li><li class="g-font-color green"><span class="g-font-color red">使得：</span>驱动</li><li class="g-font-color green"><span class="g-font-color red">网络：</span>收集</li><li class="g-font-color green"><span class="g-font-color red">消失：</span>消散 消逝 磨灭</li>
                        </ul>

                    </div>
                </div>
            </div>
        </div>
            </div>
    <div class="back-to-top text-center">
        <a href="#gototop" class="font-bold g-font-color green">回到顶部</a>
    </div>
    <div class="paper-footer">
        <p>检测报告由<a href="http://www.paperpass.com/" target="_black">PaperPass</a>文献相似度检测系统生成</p>
        <p>Copyright © 2007-2020 PaperPass</p>
    </div>
</div>
</body>
<script type="text/javascript" src="../js/jquery.min.js"></script>
<script type="text/javascript" src="../js/Lib.js"></script>
<script type="text/javascript">
    (function(System,$){
        var tab = System.Paper.tab();
        var $advice = null;
        function run(){
            var i = 0;
            $advice.show();
            tab.call(this,{callback:function(){
                var $num = $(this).find('.chapter-num');
                if($num.length>0){
                    i++;
                    $num.text(i);
                }
            }});
            //没有内容时同时不显示该句修改建议
            if(0 === i){$advice.hide();}
        }
        $(function(){
            $advice = $('#advice');
            $(document).on('click','[tab-a="ul"] li',function(){
                run.call(this);
            });
            $(document).on('click','[tab-b="ul"] li',function(){
                run.call(this);
            });
        });
    })(Report,jQuery);


</script>
</html>
